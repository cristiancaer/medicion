{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import cv2 as cv\n",
    "import os\n",
    "from calibracion import puntos\n",
    "from tabulate import tabulate\n",
    "#list_img: resive una lista de imagenes a graficar, la lista debe estar en formato vector fila\n",
    "#filas: nuermo de filas del subplot\n",
    "#colum: numero de columnas del subplot\n",
    "#Nota para graficar se debe formar una regilla mas grande o igual al numero de imagenes, pero no menor.\n",
    "#list_titulos: no es  necesario entregarla. permite colocarle entregar un titulo para cada imagen. \n",
    "def graficar(list_img,filas,colum,list_titulos=[]):\n",
    "    numero=len(list_img)\n",
    "    titulos=len(list_titulos)\n",
    "    if titulos!=numero:\n",
    "        titulos=0\n",
    "        print(\"numero de titulos incorrecto\")\n",
    "    plt.figure(figsize=(40,20))\n",
    "    for i in range(numero):\n",
    "        plt.subplot(filas,colum,i+1)\n",
    "        plt.imshow(list_img[i])\n",
    "        if titulos>0 : \n",
    "            plt.title(list_titulos[i],fontsize=40)\n",
    "           \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# capturar imagenes.\n",
    "1. las imagenes del sensor RGB para la calibracion se guardaran unicamente en escala de grises.\n",
    "2. el nombre de todas las imagenes tiene el siguiente formato sensor_numero.png. sensor=gray para las imagenes del sensor RGB, sensor=depth para el sensor de profundidad. un numero se colocara para diferenciar imagenes tomadas del mismo  sensor. el numero tambien permitira agrupar las imagenes de los dos sensores en pares que contengan el mismo numero. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ventana import ventana\n",
    "def obtener_img_calibracion(path,nueva_carpeta):\n",
    "    # initialize interface\n",
    "    interface=ventana(\"presionar f: para guardar img; c para salir\")\n",
    "    # comprobar carpeta de almacenamiento\n",
    "    #path='/home/estufab/Escritorio/flujo de bagazo/codigo/img_calibracion'\n",
    "    if  not(os.path.isdir(\"{}/{}/\".format(path,nueva_carpeta))):\n",
    "        os.mkdir(\"{}/{}\".format(path,nueva_carpeta))\n",
    "    #actualizar path\n",
    "    path+=nueva_carpeta\n",
    "    # Initialize the depth device\n",
    "    openni2.initialize()\n",
    "    dev = openni2.Device.open_any()\n",
    "\n",
    "    # Start the depth stream\n",
    "    depth_stream = dev.create_depth_stream()\n",
    "    depth_stream.start()\n",
    "    depth_stream.set_video_mode(c_api.OniVideoMode(pixelFormat = c_api.OniPixelFormat.ONI_PIXEL_FORMAT_DEPTH_100_UM, resolutionX = 640, resolutionY = 480, fps = 30))\n",
    "    rgb_stream = dev.create_color_stream()\n",
    "    rgb_stream.set_video_mode(c_api.OniVideoMode(pixelFormat=c_api.OniPixelFormat.ONI_PIXEL_FORMAT_RGB888, resolutionX= 640, resolutionY = 480, fps = 30))\n",
    "    rgb_stream.start()\n",
    "\n",
    "    def get_gray():                                                                  \n",
    "        bgr   = np.frombuffer(rgb_stream.read_frame().get_buffer_as_uint16(),dtype=np.uint8).reshape(480,640,3)\n",
    "        gray   = cv2.cvtColor(bgr,cv2.COLOR_BGR2RGB)\n",
    "        return gray\n",
    "    x=0\n",
    "    while True:\n",
    "        # Grab a new depth frame\n",
    "\n",
    "\n",
    "        img_gray = get_gray()    \n",
    "        depth = np.frombuffer(depth_stream.read_frame().get_buffer_as_uint16(),dtype=np.uint16)\n",
    "        depth.shape = (1, 480, 640)\n",
    "        depth = np.concatenate((depth, depth, depth), axis=0)\n",
    "        depth = np.swapaxes(depth, 0, 2)  #las columnas las vuelvo filas\n",
    "        depth = np.swapaxes(depth, 0, 1) # las filas las vuelvo columnas \n",
    "        #pseudo color\n",
    "        depth_copy=cv2.cvtColor(depth, cv2.COLOR_BGR2GRAY)/256\n",
    "        depth_color = cv2.applyColorMap(depth_copy.astype(np.uint8), cv2.COLORMAP_JET)#COLORMAP_JET##COLORMAP_PINK\n",
    "\n",
    "        #visualizacion\n",
    "        interface.visualizar([img_gray,depth_color],img_gray.shape[0:2],1,2,[\"RGB\",\"DEPTH\"])\n",
    "\n",
    "\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        # If the 'c' key is pressed, break the while loopc\n",
    "        if key == ord(\"c\"):\n",
    "                       break\n",
    "        if key == ord(\"f\"):\n",
    "            x+=1\n",
    "            path_gray=os.path.join(path, 'gray_{}.png'.format(x))\n",
    "            path_matrix_depth=os.path.join(path, 'gray_{}.png'.format(x))\n",
    "            path_depth_16=os.path.join(path, 'depth_{}.png'.format(x))\n",
    "            cv2.imwrite(path_depth_16,depth)\n",
    "            np.save(path_matrix_depth,depth)\n",
    "            ret=cv2.imwrite(path_gray,img_gray)\n",
    "            print(ret)\n",
    "            print (\"end-start\")\n",
    "\n",
    "    openni2.unload()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calibracion import obtener_img_calibracion\n",
    "path='/home/estufab4/Desktop/flujo de bagazo/codigo/img_calibracion/'\n",
    "nueva_carpeta=\"prb3\"\n",
    "a=obtener_img_calibracion(path,nueva_carpeta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cambiar nombre imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cambiar_nombre(path,nombre,nuevo_nombre):\n",
    "    #path=\"/home/estufab/Escritorio/flujo de bagazo/codigo/img_calibracion/RGB5/\"\n",
    "    images = glob.glob(\"{}{}*.png\".format(path,nombre))\n",
    "    for name in images:\n",
    "        index=name.find(nombre)\n",
    "        n=len(nombre)\n",
    "        nuevo=name[:index]+nuevo_nombre+name[index+n:]\n",
    "        print(nuevo)\n",
    "        os.rename(name,nuevo)\n",
    "cambiar_nombre(\"/home/estufab/Escritorio/flujo de bagazo/codigo/img_calibracion/union/\",\"deph\",\"depth\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# flip  conjunto de imagenes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path: directorio absoluto del lugar donde se almacenan las imagenes.\n",
    "#tipo: 0 para elegir flip vertical, 1 para elegir flip horizontal\n",
    "def flip(path,tipo):\n",
    "    #path=\"/home/estufab/Escritorio/flujo de bagazo/codigo/img_calibracion/RGB5/\"\n",
    "    images = glob.glob(\"{}*.png\".format(path))\n",
    "    for fname in images:\n",
    "        img =cv2.imread(fname)\n",
    "        img=np.flip(img,axis=tipo)\n",
    "        cv2.imwrite(fname,img)\n",
    "flip(\"/home/estufab/Escritorio/flujo de bagazo/codigo/img_calibracion/profundidad5/\",1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def puntos_objeto(d,nf,nc):\n",
    "   #  d distancia entre punto medio de circulos/ la multiplicación no afecta la matriz intrinseca\n",
    "    # preparar puntos de objeto, como (0,0,0), (1,0,0), (2,0,0)...., (6,5,0) \n",
    "    objp = np.zeros((nf*nc,3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:nc,0:nf].T.reshape(-1,2)# crea una grilla tipo chessboard\n",
    "\n",
    "    # formar plano cordenado teniendo en cuenta las medidas del patron y su forma asimetrica\n",
    "    objp=objp.reshape(nf,nc,3)\n",
    "    for i in range(nf): #\n",
    "      objp[i,:,1]=d*objp[i,:,1]/2# distancia entre filas\n",
    "    #distancia entre circulos de una misma fila\n",
    "      if i%2==0:\n",
    "        objp[i,:,0]=d*objp[i,:,0]\n",
    "      else:# filas desplazadas\n",
    "        objp[i,:,0]=d*objp[i,:,0]+d/2\n",
    "    objp=objp.reshape(nf*nc,3) \n",
    "    return objp\n",
    "def calibracion(objpoints,imgpoints,shape_img):\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints,shape_img[::-1],None,None)## las dimensiones que recive son de ancho por alto, por eso hay que invertir shape_img\n",
    "    # refinamiento de la matriz intrinceca, ROI con recorte de  la imagen\n",
    "    newcameramtx, roi=cv2.getOptimalNewCameraMatrix(mtx,dist,shape_img[::-1],1)\n",
    "    # calcular la inversa\n",
    "    inv_mtx=np.linalg.inv(newcameramtx)\n",
    "    total_error = 0 \n",
    "    for i in range(len(objpoints)): \n",
    "        imgpoints2, _ = cv2.projectPoints(objpoints[i], rvecs[i], tvecs[i], mtx, dist) \n",
    "        error = cv2.norm(imgpoints[i],imgpoints2, cv2.NORM_L2)/len(imgpoints2)\n",
    "    \n",
    "        print(\"error por imagen:{}\".format(error))\n",
    "        total_error += error\n",
    "    mean_error=total_error/len(objpoints)\n",
    "    print (\"error medio de reproyección en pixeles: \", mean_error )\n",
    "    return mtx,newcameramtx,roi,inv_mtx, dist, rvecs, tvecs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# calibrar RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nf=8\n",
    "nc=5\n",
    "d=20\n",
    "objp=puntos_objeto(d,nf,nc)\n",
    "\n",
    "puntos_rgb=puntos(nf,nc)\n",
    "path=\"/home/estufab4/Desktop/flujo de bagazo/codigo/img_calibracion/RGB5/\"\n",
    "images = glob.glob(\"{}gray_*.png\".format(path))\n",
    "# Arrays para almacenar puntos de objeto y puntos de imagen de todas las imágenes.\n",
    "objpoints = [] # 3d point in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "# extracción de puntos para todas las imagenes\n",
    "for fname in images:\n",
    "    #show paht and name of picture \n",
    "    print(fname)\n",
    "    img =cv2.imread(fname)\n",
    "    #img=np.flip(img,axis=0)\n",
    "    ret,puntos_centro,_=puntos_rgb.extraer(img)\n",
    "    print(\"hubo detección: {}\".format(ret))\n",
    "    if ret:\n",
    "        # agregar puntos para la calibración\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(puntos_centro)\n",
    "        #dibujar puntos encontrados\n",
    "        img_centers=puntos_rgb.dibujar(img,puntos_centro)\n",
    "        #graficar resultados\n",
    "        graficar(list_img=[img,img_centers],\n",
    "                 filas=1,colum=2,list_titulos=[\"original\",\"puntos centro\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#proceso de calibración\n",
    "print(img.shape[:2])\n",
    "mtx,newcameramtx,roi,inv_mtx, dist, rvecs, tvecs=calibracion(objpoints,imgpoints,img.shape[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# crear clase calibracion_uv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calibracion import puntos,graficar\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from configparser import ConfigParser\n",
    "# la clase solo realiza calibración de la informacion en las cordenadas uv de la imagen.\n",
    "## la clase permite encontrar la matriz intrinseca y una versión optimizada de la misma. la clase tiene por separado las funciones de resultados y funsiones de visualización.\n",
    "#la clase tiene una función que permite quitar la distorsion causada por los lentes, tambien quitar la distorción a todas las imagenes utilizadas para la calibración y las guarda con el titulo de la imagen original dentro de la subcarpeta distorción\n",
    "# las imagenes deben estar guardadas con un nombre que posea el siguente formato.  cabecera_nombre.png. cabecera=gray indica si la imagen es RGB o cabecera=depth de profunidad. nombre puede adquirir cualquier valor.\n",
    "# la clase puede calibrar informacion uv tanto para RGB como para profundidad. solo hay que cambiar el typo en el costructor. typo=0 RGB, tipo=1 profundidad.\n",
    "# la clase permite guardar la informacion en urchivo .ini. se escoge este formato por dos razones. primero al almacenar la informacion con tiquetas, se  facilita  localizar cualquier dato. se puede editar las etiquetas facilmente, alterando solo la informacion requerita. esto ultimo permite agrupar toda la informacion de configuración en un solo archivo.\n",
    "# al utilizar el tipo de archivo .ini toda la informacion se guarda en formato string. si bien habrá que reconvertirla a tipo array, se podra abrir el archivo cualquier editor de texto.\n",
    "class calibracion_uv(puntos):\n",
    "    \n",
    "\n",
    "    #constructor\n",
    "    #path:carpeta donde se encuentra la carpeta de imagenes. la dirección es absoluta. las imagenes deben estar guardadas con nombre de formato (tipo_indicativo.png). tipo podra ser gray o depht.\n",
    "    #indicativo puede ser cualquier cosa para identificar a la imagen( un numero, una fecha etc..)\n",
    "    #path: directorio absoluto donde se encentran las imagenes a guardar.\n",
    "    #d: diametro de los circulos\n",
    "    #nf: numero de filas\n",
    "    #nc:numero de circulos por fila\n",
    "    #tipo: indicador 0 Para RGB, 1 Para profundidad.\n",
    "    def __init__(self,path,d,nf,nc,tipo=0):\n",
    "\n",
    "        #constantes de intancia\n",
    "        self.d=d# diametro de circulos\n",
    "        self.nf=nf\n",
    "        self.nc=nc\n",
    "        self.tipo=tipo\n",
    "        self.path=path\n",
    "        #variables de instancia\n",
    "        self.mtx=0# matriz intrinseca \n",
    "        self.mt_intrinseca=0# matriz intrinseca optimizada\n",
    "        self.mt_inv=0# almacena la matriz inversa de la matriz intrinseca\n",
    "        self.dist=0# almacena los coeficientes de distorción\n",
    "        self.roi=0# almacena el area de interes, util para quitar la distorción \n",
    "        self.list_puntos_img=[]# cada elemento pertenece a una imagen diferente, cada elemento es una matriz con los puntos encontrados en la imagen.\n",
    "        self.list_puntos_obj=[]# debe haber un elemento por cada elemento en list_puntos_img. todos los elementos en esta lista son iguales.\n",
    "        self.list_nombres_img=[]# contiene una lista de la ruta y nombre  de las imagenes en la que los puntos fueron detectados. hay correspondencia uno a uno con lis_puntos_img\n",
    "        self.list_error_img=[]# cada elemento tiene una correspondencia uno a uno con list_nombres_img. cada elementos es error promedio de proyección en pixeles de los puntos de una imagen. \n",
    "        self.error_promedio=0# contiene el error promedio de proyección, se calcula con respecto a todas las imagenes. En otras palabras es el promedio de los valores en list_error_img\n",
    "        self.puntos_obj=self.puntos_objeto()\n",
    "        self.img_shape=0#  contiene (alto,ancho)\n",
    "        #funciones \n",
    "        puntos.__init__(self,nf,nc)# constructor de la clase puntos.\n",
    "        self.obtener_puntos_img()\n",
    "       \n",
    "       \n",
    "    def puntos_objeto(self):\n",
    "        #d distancia entre punto medio de circulos/ la multiplicación no afecta la matriz intrinseca\n",
    "        # preparar puntos de objeto, como (0,0,0), (1,0,0), (2,0,0)...., (6,5,0) \n",
    "        objp = np.zeros((self.nf*self.nc,3), np.float32)\n",
    "        objp[:,:2] = np.mgrid[0:self.nc,0:self.nf].T.reshape(-1,2)# crea una grilla tipo chessboard\n",
    "\n",
    "        # formar plano cordenado teniendo en cuenta las medidas del patron y su forma asimetrica\n",
    "        objp=objp.reshape(self.nf,self.nc,3)\n",
    "        for i in range(self.nf):\n",
    "            # distancia entre filas\n",
    "          objp[i,:,1]=self.d*objp[i,:,1]\n",
    "        #distancia entre circulos de una misma fila\n",
    "          if i%2==0:\n",
    "            objp[i,:,0]=self.d*2*objp[i,:,0]\n",
    "          else:# filas desplazadas\n",
    "            objp[i,:,0]=self.d*2*objp[i,:,0]+self.d\n",
    "        objp=objp.reshape(self.nf*self.nc,3) \n",
    "        return objp\n",
    "    def obtener_puntos_img(self):\n",
    "        if self.tipo==1:\n",
    "            directorio = glob.glob(\"{}depth_*.png\".format(self.path))\n",
    "        else:\n",
    "            directorio = glob.glob(\"{}gray_*.png\".format(self.path))\n",
    "        \n",
    "   \n",
    "        for name in directorio:\n",
    "       \n",
    "            #show paht and name of picture \n",
    "            print(name)\n",
    "            img =cv2.imread(name)\n",
    "            #img=np.flip(img,axis=1)\n",
    "            ret,puntos_centro,_=self.extraer(img,self.tipo)\n",
    "            print(\"hubo detección: {}\".format(ret))\n",
    "            if ret:\n",
    "                # agregar puntos para la calibración\n",
    "                self.list_puntos_img.append(puntos_centro)\n",
    "                self.list_puntos_obj.append(self.puntos_obj)\n",
    "                self.list_nombres_img.append(name)\n",
    "            #actualizar las dimensiones de las imagenes\n",
    "            self.shape_img=img.shape[:2]\n",
    "        \n",
    "        if len(self.list_puntos_img)==0:\n",
    "                print(\"no hubo deteccion\")\n",
    "        else:\n",
    "            \n",
    "            # modificacion para impidir procesar mas de 100 img\n",
    "            cnt=int(len(self.list_puntos_img)/100 +1)\n",
    "            self.list_puntos_img=self.list_puntos_img[::cnt]\n",
    "            self.list_puntos_obj=self.list_puntos_obj[::cnt]\n",
    "            print(\"numero de imagenes a utilizar : \",len(self.list_puntos_img))\n",
    "    def calibrar(self):\n",
    "        if len(self.list_puntos_img)>0:\n",
    "            print(\"calculando parametros...\")\n",
    "            ret, self.mtx, self.dist, rvecs, tvecs = cv2.calibrateCamera(self.list_puntos_obj,self.list_puntos_img,self.shape_img[::-1],None,None)## las dimensiones que recive son de ancho por alto, por eso hay que invertir gray.shape\n",
    "            # refinamiento de la matriz intrinceca, ROI con recorte de  la imagen\n",
    "            self.mt_intrinseca, self.roi=cv2.getOptimalNewCameraMatrix(self.mtx,self.dist,self.shape_img[::-1],1)\n",
    "            self.roi=np.array(self.roi)# almacenar como un array numpy\n",
    "            # calcular la inversa\n",
    "            self.mt_inv=np.linalg.inv( self.mt_intrinseca)\n",
    "            total_error = 0 \n",
    "            for i in range(len(self.list_puntos_img)): \n",
    "                imgpoints2, _ = cv2.projectPoints(self.list_puntos_obj[i], rvecs[i], tvecs[i],self.mtx, self.dist) \n",
    "                error = cv2.norm(self.list_puntos_img[i],imgpoints2, cv2.NORM_L2)/len(imgpoints2)\n",
    "                self.list_error_img.append(error)\n",
    "                total_error += error\n",
    "            self.list_error_img=np.array(self.list_error_img)\n",
    "            self.error_promedio=total_error/len(self.list_puntos_img)\n",
    "            print (\"error medio de reproyección en pixeles: \", self.error_promedio )\n",
    "        else:\n",
    "            print(\"no hubo ninguna detección\")\n",
    "    # cada elemento es un par de imagenes. una imagen original y una modificada.La imagen modificada tiene los puntos detectados.\n",
    "    def dibujar_puntos(self):\n",
    "        list_img=[]\n",
    "        for i in range(len(self.list_nombres_img)):\n",
    "            img =cv2.imread(self.list_nombres_img[i])\n",
    "            #img=np.flip(img,axis=1)\n",
    "            img_puntos=self.dibujar(img,self.list_puntos_img[i],0)\n",
    "            list_img.append([img,img_puntos])\n",
    "        return list_img\n",
    "    #resive una imagen y devuelve una imagen sin distorsión teniendo en cuenta los paratros de la camara obtenidos durante la calibración \n",
    "    def distorsion(self,img):\n",
    "        dst = cv2.undistort(img, self.mtx, self.dist, None, self.mt_intrinseca)\n",
    "        return dst\n",
    "    # distorsiona todas la imagenes utilizadas para la calibración y las guarda en una subcarpeta llamada distorsion\n",
    "    def distorsion_imgs(self):\n",
    "        #comprobar existencia de la carpeta distorsion\n",
    "        if  not(os.path.isdir(\"{}/distorsion/\".format(self.path))):\n",
    "            os.mkdir(\"{}distorsion\".format(self.path))\n",
    "            \n",
    "        for name in self.list_nombres_img:\n",
    "            img =cv2.imread(name)\n",
    "            img_dst=self.distorsion(img)\n",
    "            # recortar imagen \n",
    "            #x,y,w,h = self.roi\n",
    "            #img_dst = img_dst[y:y+h, x:x+w]\n",
    "            if self.tipo:\n",
    "                index=name.find(\"depth\")# debido a que en el nombre de la imagen tiene el indicador de gray o depht. se puede extraer el nombre de la dirección y volver a guardar la imagen a la que se le quita el la distorción con el mismo nombre.\n",
    "                cv2.imwrite(\"{}distorsion/{}\".format(self.path,name[index:]),img_dst)\n",
    "            else:\n",
    "                index=name.find(\"gray\")# debido a que en el nombre de la imagen tiene el indicador de gray o depht. se puede extraer el nombre de la dirección y volver a guardar la imagen a la que se le quita el la distorción con el mismo nombre.\n",
    "                cv2.imwrite(\"{}distorsion/{}\".format(self.path,name[index:]),img_dst)\n",
    "   #la iformacion se guarda en un archivo .ini. que puede ser leido por cualquier editor de texto\n",
    "    #toda la informacion se guarda como string, por eso habra que reconvertir cuando se guarden los datos\n",
    "    #nombre: solo nombre de archivo sin extension\n",
    "    #path: dirección absoluta del lugar donde se quiere guardar. si no se especifica el archivo se guardara en la carpeta donde se esta ejecutando el archivo .py\n",
    "    def guardar(self,nombre,path=\"\"):\n",
    "        #crear objeto\n",
    "        config = ConfigParser()\n",
    "        #revisar existencia del archivo\n",
    "        ret=config.read('{}{}.ini'.format(path,nombre))\n",
    "        if ret: #verificar si el objeto esta vacio\n",
    "            ret=True\n",
    "        else:\n",
    "            ret=False\n",
    "        #configurar tipo de información rgb o de profundidad\n",
    "        if self.tipo:\n",
    "            tipo=\"depth\"\n",
    "        else:\n",
    "            tipo=\"rgb\"\n",
    "        print(config)\n",
    "        #toda la informacion se convierte a vector fila para facilitar luego su lectura.   \n",
    "        config['calibracion_uv_{}'.format(tipo)] = {\"mtx\": self.mtx.reshape(-1),\n",
    "                                                    \"mt_intrinseca\":self.mt_intrinseca.reshape(-1),\n",
    "                                                    \"mt_inversa\": self.mt_inv.reshape(-1),\n",
    "                                                    \"coef_dist\":self.dist.reshape(-1),\n",
    "                                                    \"roi\":self.roi.reshape(-1),\n",
    "                                                    \"error\":self.error_promedio\n",
    "                                   }\n",
    "        \n",
    "        #guardar archivo\n",
    "        with open('{}{}.ini'.format(path,nombre), 'w') as configfile:\n",
    "            config.write(configfile)\n",
    "        return ret\n",
    "        \n",
    "\n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# utilizar clase calibración_uv para RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nf=9\n",
    "nc=6\n",
    "d=5\n",
    "path=\"/home/estufab4/Desktop/flujo de bagazo/codigo/img_calibracion/calibracion2/d5_110/\"\n",
    "calibracion_rgb=calibracion_uv(path,d,nf,nc,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# visualización de las imagenes detectadas y sus puntos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_img=calibracion_rgb.dibujar_puntos()\n",
    "for i in range(len(list_img)):\n",
    "    directorio_img=calibracion_rgb.list_nombres_img[i]\n",
    "    index=directorio_img.find(\"gray\")\n",
    "    nombre_img=directorio_img[index:]\n",
    "    graficar(list_img[i],1,2,[nombre_img,\"imagen con puntos\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# si todas las imagenes son correctas se procede a utilizarlas para calibrar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibracion_rgb.calibrar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# error proyección en px por imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "tabla=zip(calibracion_rgb.list_nombres_img,calibracion_rgb.list_error_img)\n",
    "print(tabulate(tabla,headers=[\"imagen\",\"error en px\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quitar distorsión a todas las imagenes de la calibración, ver carpeta path/distorsión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibracion_rgb.distorsion_imgs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guardar datos calibracion UV para RGB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibracion_rgb.guardar(\"distorsion_uvz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# calibración profundidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nf=9\n",
    "nc=6\n",
    "d=5\n",
    "path=\"/home/estufab4/Desktop/flujo de bagazo/codigo/img_calibracion/uv_d5_50/\"\n",
    "calibracion_depth=calibracion_uv(path,d,nf,nc,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# visualización de las imagenes detectadas y sus puntos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list_img=calibracion_depth.dibujar_puntos()\n",
    "for i in range(len(list_img)):\n",
    "    directorio_img=calibracion_depth.list_nombres_img[i]\n",
    "    print(directorio_img)\n",
    "    index=directorio_img.find(\"depth\")\n",
    "    nombre_img=directorio_img[index:]\n",
    "    graficar(list_img[i],1,2,[nombre_img,\"imagen con puntos\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# calcular parametros si todas las imagenes fueron correctamente detectados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibracion_depth.calibrar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# error de proyección por imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  tabulate import tabulate\n",
    "tabla=zip(calibracion_depth.list_nombres_img,calibracion_depth.list_error_img)\n",
    "print(tabulate(tabla,headers=[\"imagen\",\"error en px\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quitar distorsión a todas las imagenes de la calibración, ver carpeta path/distorsión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibracion_depth.distorsion_imgs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# guardar datos calibracion uv para profundidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibracion_depth.guardar(\"distorsion_uvz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# crear clase RGB2DEPTH\n",
    "1. la clase encuentra la matriz homografica entre los sensores RGB y Profundidad\n",
    "2. la clase tiene por separado las funciones de resultados y funsiones de visualización.\n",
    "3.  las imagenes deben estar guardadas con un nombre que posea el siguente formato.  cabecera_numero.png. cabecera=gray indica si la imagen es RGB o cabecera=depth de profunidad. numero puede adquirir cualquier valor.\n",
    "4. el contructor de la clase resive: path=dirección absoluta del lugar en donde se encuentran las imagenes\n",
    "5. nf: numero de filas que posee el patron\n",
    "6. nc: numero de circulos que tiene el patron por fila.\n",
    "7. para saber que tan buena es la matriz hayada, se encuentra el error promedio de todas las imagenes. el valor promedio es encontrado llevando la informacion RGB del patron al dominio del sensor de profundidad, alli se calculan la posición de los puntos y se los compara con los ayados directamente de la imagen de profundidad\n",
    "8. los sensores de las imagenes estan fijos, en el caso ideal todas las matrices hograficas hayadas  por cada par de imagenes deberian ser iguales, sin embargo debido al ruido de la escena habra variaciones entre ellas. Para quitar el ruido se se calcula un promedio entre todas las homografias encontradas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calibracion import *\n",
    "#la clase encuentra la matriz homografica entre los sensores RGB y Profundidad\n",
    "# la clase tiene por separado las funciones de resultados y funsiones de visualización.\n",
    "# las imagenes deben estar guardadas con un nombre que posea el siguente formato.  cabecera_numero.png. cabecera=gray indica si la imagen es RGB o cabecera=depth de profunidad. numero puede adquirir cualquier valor.\n",
    "# el contructor de la clase resive: path=dirección absoluta del lugar en donde se encuentran las imagenes\n",
    "#nf: numero de filas que posee el patron\n",
    "#nc: numero de circulos que tiene el patron por fila.calibracion_rgb.mt_inv,\n",
    "#para saber que tan buena es la matriz hayada, se encuentra el error promedio de todas las imagenes. el valor promedio es encontrado llevando la informacion RGB del patron al dominio del sensor de profundidad, alli se calculan la posición de los puntos y se los compara con los ayados directamente de la imagen de profundidad\n",
    "# la clase permite guardar la informacion en urchivo .ini. se escoge este formato por dos razones. primero al almacenar la informacion con tiquetas, se  facilita  localizar cualquier dato. se puede editar las etiquetas facilmente, alterando solo la informacion requerita. esto ultimo permite agrupar toda la informacion de configuración en un solo archivo.\n",
    "# al utilizar el tipo de archivo .ini toda la informacion se guarda en formato string. si bien habrá que reconvertirla a tipo array, se podra abrir el archivo cualquier editor de texto.\n",
    "\n",
    "class homografia_rgb_depth(puntos):\n",
    "    def __init__(self,path,nf,nc):\n",
    "        self.path=path# carpeta direccion absoluta de almacenamiento de las imagenes\n",
    "        self.nf=nf# numero de filas del patron\n",
    "        self.nc=nc# numero de circulos por fila.\n",
    "        self.list_puntos_img=[]# cada elemento estara compunto de 3 matrices. puntos rgb, puntos depth, puntos de imgen rgb en el dominio de depth\n",
    "        self.list_nombres_img=[]# se almacena solo el  numero (nombre=cabecera_numero) de las imagenes detectadas\n",
    "        self.homografia=0\n",
    "        self.error_promedio=0\n",
    "        self.error_img=[]# se almacena el error promedio de los puntos por cada imagen\n",
    "         #funciones \n",
    "        puntos.__init__(self,nf,nc)# constructor de la clase puntos.\n",
    "        self.calcular_homografia()\n",
    "    # abre el par de imagenes de correspondan a la misma escena.\n",
    "    #devuelve 1 si encuentra el par, 0 caso contrario\n",
    "    def abrir_par_img(self,indicador1,indicador2,nombre):\n",
    "        path_1=os.path.join(self.path, '{}_{}.png'.format(indicador1,nombre))\n",
    "        path_2=os.path.join(self.path, '{}_{}.png'.format(indicador2,nombre))\n",
    "        #confirmar existencia de ambas imagenes\n",
    "        ret_2=cv2.haveImageReader(path_2)\n",
    "        ret_1=cv2.haveImageReader(path_1)\n",
    "      \n",
    "        img_1=0;img_2=0;\n",
    "        ret=ret_1*ret_2#\n",
    "        if ret:\n",
    "            img_2=cv2.imread(path_2)\n",
    "            img_1=cv2.imread(path_1)\n",
    "           \n",
    "        return ret,img_1,img_2\n",
    "    \n",
    "    def calcular_homografia(self):\n",
    "        for i in range(1000):\n",
    "            ret,img_gray,img_depth=self.abrir_par_img(\"gray\",\"depth\",i)\n",
    "            #print(ret,img_gray,img_depth)\n",
    "            if ret:\n",
    "                #encontrar puntos\n",
    "                ret_gray,puntos_gray,_=self.extraer(img_gray,0)\n",
    "                ret_depth,puntos_depth,_=self.extraer(img_depth,1)\n",
    "                ret=ret_depth*ret_gray\n",
    "                \n",
    "                print(\"en imagen numero {} hubo detección de puntos:{}\".format(i,bool(ret)))\n",
    "                if ret:\n",
    "                    #agregar puntos\n",
    "                    self.list_puntos_img.append([puntos_gray,puntos_depth,0])\n",
    "                    #agregar nombre de las imagenes detectadas.\n",
    "                    self.list_nombres_img.append(i)\n",
    "                    #encontrar homografia por cada par de imagenes\n",
    "                    h,ret=cv2.findHomography(puntos_gray, puntos_depth)# puntos fuente, puntos en el destino\n",
    "                    img_gray_2depth= cv2.warpPerspective(img_gray, h, (img_gray.shape[1], img_gray.shape[0]))#primero ancho y luego alto\n",
    "                    self.homografia+=h\n",
    "                \n",
    "        #eliminar ruido mediante promedio\n",
    "        self.homografia/=len(self.list_nombres_img)+1\n",
    "        #convertir todas las imagenes RGB detectadas al dominio de profundidad\n",
    "        self.convertir_rgb_depth()\n",
    "    #entrega una lista donde cada elemento tiene 4 imagenes. img_gray: RGB orginal. img_puntos_gray: imagen RGB con puntos detectados. \n",
    "    def dibujar_puntos_homografia(self):\n",
    "        list_img=[]\n",
    "        for i in range(len(self.list_nombres_img)):\n",
    "            ret,img_gray,img_depth =self.abrir_par_img(\"gray\",\"depth\",self.list_nombres_img[i])\n",
    "            img_puntos_gray=self.dibujar(img_gray,self.list_puntos_img[i][0],0)\n",
    "            img_puntos_depth=self.dibujar(img_depth,self.list_puntos_img[i][1],0)\n",
    "            list_img.append([img_gray,img_puntos_gray,img_depth,img_puntos_depth])\n",
    "        return list_img\n",
    "    #a cada imagen de profundidad se le dibujan los puntos detectados en la RGB con cambio de dominio.\n",
    "    def dibujar_puntos(self):\n",
    "        list_img=[]\n",
    "        for i in range(len(self.list_nombres_img)):\n",
    "            path_gray_depth=os.path.join(self.path, 'depth_{}.png'.format(self.list_nombres_img[i]))\n",
    "            img_gray_depth=cv2.imread(path_gray_depth)\n",
    "            img_puntos_depth=self.dibujar(img_gray_depth.copy(),self.list_puntos_img[i][2],0)\n",
    "            list_img.append([img_gray_depth,img_puntos_depth])\n",
    "        return list_img\n",
    "   #convierte todas las imagenes RGB detectadas al dominio de profundidad. las imagenes son guardadas con nombre de formato gray_2depth_numero. \n",
    "    def convertir_rgb_depth(self):\n",
    "        for i in range(len(self.list_nombres_img)):\n",
    "            path_gray=os.path.join(self.path, 'gray_{}.png'.format(self.list_nombres_img[i]))\n",
    "            img_gray=cv2.imread(path_gray)\n",
    "            #cambiar de dominio\n",
    "            img_gray_2depth= cv2.warpPerspective(img_gray, self.homografia, (img_gray.shape[1], img_gray.shape[0]))#primero ancho y luego alto\n",
    "            #extraer puntos en nuevo dominio\n",
    "            ret,puntos_rgb_depth,_=self.extraer(img_gray_2depth,0)\n",
    "            #guardar puntos\n",
    "            self.list_puntos_img[i][2]=puntos_rgb_depth\n",
    "            if ret:\n",
    "                #calcular error\n",
    "                error_img=cv2.norm(self.list_puntos_img[i][1],puntos_rgb_depth, cv2.NORM_L2)/len(puntos_rgb_depth)\n",
    "                self.error_img.append(error_img)\n",
    "            else:\n",
    "                self.error_img.append(5)\n",
    "            #guardar imagenes \n",
    "            path_gray_2depth=os.path.join(self.path, 'gray2_depth_{}.png'.format(self.list_nombres_img[i]))\n",
    "            cv2.imwrite(path_gray_2depth,img_gray_2depth)\n",
    "        self.error_img=np.array(self.error_img)\n",
    "        self.error_promedio=np.mean(self.error_img)\n",
    "        print(\"el error de proyección promedio. {}\".format(self.error_promedio))\n",
    "    # guarda en un archivo .ini la informacion de la matriz homografica encontrada y el error de proyecció promedio\n",
    "    # toda la informacion se coloca en vector columna antes de guardarla\n",
    "    def guardar(self,nombre,path=\"\"):\n",
    "        config = ConfigParser()\n",
    "        #revisar existencia del archivo\n",
    "        ret=config.read('{}{}.ini'.format(path,nombre))\n",
    "        if ret:# comprobar objeto vacio\n",
    "            ret=True\n",
    "        else:\n",
    "            ret=False\n",
    "        config['homografia'] = {'homografia': self.homografia.reshape(-1),\n",
    "                                   \"error\":self.error_promedio\n",
    "                                   }\n",
    "        #guardar archivo\n",
    "        with open('{}{}.ini'.format(path,nombre), 'w') as configfile:\n",
    "            config.write(configfile)\n",
    "        return ret\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calibracion import *\n",
    "rgb_depth=homografia_rgb_depth(\"/home/estufab4/Desktop/flujo de bagazo/codigo/img_calibracion/uv_d10_110_1/distorsion/\",8,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# error de proyección promedio en pixeles  por imagenes\n",
    "1. se ha asignado un error de 5px a las imagenes que no fueron detectadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error=zip(rgb_depth.error_img,rgb_depth.list_nombres_img)\n",
    "for e in error:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# visualizacion de puntos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_img=rgb_depth.dibujar_puntos_homografia()\n",
    "for i in range(len(list_img)):\n",
    "    nombre_img=format(rgb_depth.list_nombres_img[i])# colocar numero en formato string\n",
    "    graficar(list_img[i],2,2,[\"RGB \"+ (nombre_img),\"imagen RGB con puntos\",\"profundidad \"+(nombre_img),\"imagen profundidad con puntos\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# visualización cambio de dominio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_img=rgb_depth.dibujar_puntos()\n",
    "#print(list_img)\n",
    "for i in range(len(list_img)):\n",
    "    nombre_img=format(rgb_depth.list_nombres_img[i])# colocar numero en formato string\n",
    "   \n",
    "    graficar(list_img[i],1,2,[\"imagen depth\"+nombre_img,\"puntos RGB en depth\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# guaradar informacion de homografia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_depth.guardar(\"configuracion_d10_110_1_p2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from calibracion import *\n",
    "from tabulate import tabulate\n",
    "nf=8\n",
    "nc=5\n",
    "d=10\n",
    "carpeta=\"d10_150\"\n",
    "path=\"/home/estufab4/Desktop/flujo de bagazo/codigo/img_calibracion/calibracion2/{}/\".format(carpeta)\n",
    "nombre_config=\"configuracion_{}\".format(carpeta)\n",
    "def calibracion(nf,nc,d,path,nombre_config):\n",
    "    #RGB\n",
    "    calibracion_rgb=calibracion_uv(path,d,nf,nc,0)\n",
    "    calibracion_rgb.calibrar()\n",
    "    calibracion_rgb.distorsion_imgs()\n",
    "    from tabulate import tabulate\n",
    "    tabla=zip(calibracion_rgb.list_nombres_img,calibracion_rgb.list_error_img)\n",
    "    print(tabulate(tabla,headers=[\"imagen\",\"error en px\"]))\n",
    "    calibracion_rgb.guardar(nombre_config)\n",
    "    #depth\n",
    "    calibracion_depth=calibracion_uv(\"{}\".format(path),d,nf,nc,1)\n",
    "    calibracion_depth.calibrar()\n",
    "    calibracion_depth.distorsion_imgs()\n",
    "    tabla=zip(calibracion_depth.list_nombres_img,calibracion_depth.list_error_img)\n",
    "    print(tabulate(tabla,headers=[\"imagen\",\"error en px\"]))\n",
    "    calibracion_depth.guardar(nombre_config)\n",
    "    #fusion \n",
    "    rgb_depth=homografia_rgb_depth(\"{}/distorsion/\".format(path),nf,nc)\n",
    "    error=zip(rgb_depth.error_img,rgb_depth.list_nombres_img)\n",
    "    print(tabulate(error))\n",
    "    rgb_depth.guardar(nombre_config)\n",
    "calibracion(nf,nc,d,path,nombre_config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from skimage import morphology\n",
    "\n",
    "def segmenter( rgb_img: np.ndarray, black_object=True) -> np.ndarray:\n",
    "    move_thr = 0.3\n",
    "    gray_img=cv2.cvtColor(rgb_img.copy(), cv2.COLOR_RGB2GRAY)\n",
    "    thr,mask =cv2.threshold(gray_img,0,1,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    mascara = np.zeros_like(gray_img, dtype= bool)\n",
    "    if black_object:\n",
    "        mascara[gray_img<=thr*(1 + move_thr)] = True \n",
    "    else:\n",
    "        mascara[gray_img>=thr*(1 - move_thr)] = True\n",
    "            \n",
    "    mascara.dtype=bool# remove_small only works with  bool datatype\n",
    "    mascara=morphology.remove_small_objects(mascara,50,connectivity=1)\n",
    "    mascara.dtype=np.uint8\n",
    "    return mascara"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# circle detector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "def fill_image(binary):\n",
    "    src = binary.copy()   # Primero crea una copia\n",
    "    mask = np.zeros([src.shape[0]+2, src.shape[1]+2, 1], np.uint8)   # Cree una mÃ¡scara de acuerdo con la forma de la copia. Tenga en cuenta que la longitud y el ancho deben ser +2, y el tipo solo puede ser uint8\n",
    "    cv2.floodFill(src, mask, (0, 0), (255, 255, 255), (50,50,50), (50,50,50), cv2.FLOODFILL_FIXED_RANGE)\n",
    "    src = cv2.bitwise_not(src)\n",
    "    filled_img =  src\n",
    "    return filled_img\n",
    "\n",
    "class Segmenter:\n",
    "    def __init__(self)->None:\n",
    "        self.shape = 0\n",
    "    def get_detector(self):\n",
    "        total_pixels = self.shape[0]*self.shape[1]\n",
    "        blobParams = cv2.SimpleBlobDetector_Params()\n",
    "\n",
    "        # # Filter by Area.\n",
    "        blobParams.filterByArea = True\n",
    "        blobParams.minArea = 0.005*total_pixels  # minArea may be adjusted to suit for your experiment\n",
    "        blobParams.maxArea = 0.04*total_pixels # maxArea may be adjusted to suit for your experiment\n",
    "        self.detector = cv2.SimpleBlobDetector_create(blobParams)\n",
    "        \n",
    "    def get_mask (self, rgb_img):\n",
    "        # update segmenter if the shape change\n",
    "        if self.shape != rgb_img.shape[:2]:\n",
    "            self.shape = rgb_img.shape[:2]\n",
    "            self.get_detector()\n",
    "            \n",
    "        points = self.detector.detect(rgb_img)\n",
    "        mask = np.zeros(self.shape, dtype=np.uint8)\n",
    "        print('shape',mask.shape)\n",
    "        for p in points:\n",
    "            x,y=p.pt\n",
    "            mask=cv2.circle(mask, (int(x),int(y)), radius=int(p.size/(2)), color=(1,0,0), thickness=-1)\n",
    "        return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data calibrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    import numpy as np\n",
    "    class Calibration:\n",
    "        depth_matrix:np.ndarray\n",
    "        def __init__(self)->None:\n",
    "            self.setup_values()\n",
    "            \n",
    "        def setup_values(self):\n",
    "            self.fx = self.depth_matrix[0, 0]\n",
    "            self.fy = self.depth_matrix[1, 1]\n",
    "            self.depth_inv = np.linalg.inv(self.depth_matrix)\n",
    "    class Calibration640_480(Calibration) :\n",
    "        depth_matrix  = np.array([[389.127, 0, 321.047],\n",
    "                                [0, 389.127, 241.991],\n",
    "                                [0,       0,       1],\n",
    "                                ])\n",
    "        def __init__(self)->None:\n",
    "            super().__init__()\n",
    "            \n",
    "        \n",
    "    calibration640_480 = Calibration640_480()\n",
    "\n",
    "    class Calibration848_480(Calibration) :\n",
    "        depth_matrix  = np.array([[429.661, 0, 425.156],\n",
    "                                [0, 429.661, 242.199],\n",
    "                                [0,       0,       1],\n",
    "                                ])\n",
    "        def __init__(self)->None:\n",
    "            super().__init__()\n",
    "\n",
    "    calibration848_480 = Calibration848_480()\n",
    "    calibration848_480.depth_inv  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# new calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class Calibration640_480N(Calibration) :\n",
    "    depth_matrix  = np.array([[388.732, 0, 321.437],\n",
    "                              [0, 388.732, 241.958],\n",
    "                              [0,       0,       1],\n",
    "                              ])\n",
    "    def __init__(self)->None:\n",
    "        super().__init__()\n",
    "        \n",
    "    \n",
    "Calibration640_480N = Calibration640_480N()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get reference plane. Background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "def segmenter( rgb_img: np.ndarray, move_thr = 0.1, black_object=True) -> np.ndarray:\n",
    "    gray_img =cv2.cvtColor(rgb_img.copy(), cv2.COLOR_RGB2GRAY)\n",
    "    thr,mask =cv2.threshold(gray_img,0,1,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    mask = np.zeros_like(gray_img, dtype= bool)\n",
    "    if black_object:\n",
    "        mask[gray_img<=thr*(1 + move_thr)] = True \n",
    "    else:\n",
    "        mask[gray_img>=thr*(1 - move_thr)] = True\n",
    "            \n",
    "    mask.dtype=bool# remove_small only works with  bool datatype\n",
    "    mask=morphology.remove_small_objects(mask,50,connectivity=1)\n",
    "    mask.dtype=np.uint8\n",
    "    return mask\n",
    "\n",
    "class MakeBackgroundBasic:\n",
    "    shape = None\n",
    "    def make_uv_cords(self, shape):\n",
    "        self.shape = shape\n",
    "        self.v, self.u = np.mgrid[0:shape[0],0:shape[1]]\n",
    "        self.u = self.u.reshape(-1)\n",
    "        self.v = self.v.reshape(-1)\n",
    "        \n",
    "    def get_img_points (self, depth_img,  mask):\n",
    "        if self.shape != depth_img.shape:\n",
    "            self.make_uv_cords(depth_img.shape)\n",
    "        mask = mask.reshape(-1)\n",
    "        depth_row = depth_img.reshape(-1)\n",
    "        index = np.where(mask==1)\n",
    "        depth_row= depth_row[index].reshape(-1,1)\n",
    "        u = self.u[index]\n",
    "        v = self.v[index]\n",
    "        uv = np.vstack((u,v)).T\n",
    "        return uv,depth_row\n",
    "    \n",
    "    def get_background_img(self):\n",
    "        pass\n",
    "    \n",
    "    def save(self,path,name, background_img):\n",
    "        cv2.imwrite(f'{path}{name}.png',background_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From one image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "class MakeBackgroundOneImg(MakeBackgroundBasic):\n",
    "    def get_background_img(self, depth_img:np.ndarray, mask: Optional[np.ndarray]=None):\n",
    "        if mask is None:\n",
    "            mask = self.segment_by_mean_depth(depth_img)\n",
    "        uv, depth_row = self.get_img_points(depth_img, mask)\n",
    "        model = linear_model.LinearRegression()\n",
    "        # train model\n",
    "        model.fit(uv,depth_row)\n",
    "        UV = np.vstack((self.u,self.v)).T # shape = (u*v,2)\n",
    "        background_row = model.predict(UV)\n",
    "        background_img = background_row.reshape(self.shape)\n",
    "        background_img = np.round(background_img,0)\n",
    "        background_img = np.uint16(background_img)\n",
    "        return background_img\n",
    "    \n",
    "    def segment_by_mean_depth(self, depth_img):\n",
    "        \"\"\"this will consider that the background is predominant in the scene.\n",
    "        Returns:\n",
    "            background_mask: _description_\n",
    "        \"\"\"\n",
    "        depth_3 = cv2.merge((depth_img,depth_img,depth_img))# to have more points if the background is dominant, will be added more background points\n",
    "        mean_threshold = depth_3.mean() - 2*depth_3.std()\n",
    "        background_mask = np.zeros_like(depth_img)\n",
    "        background_mask[depth_img>=mean_threshold] = 1\n",
    "        return background_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From multiple images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from skimage import morphology\n",
    "from sklearn import linear_model\n",
    "import sys# las sisguientes dos lineas ayudan a ubicar al archivo calibracion.py\n",
    "sys.path.append(\"/home/ingelec2/Desktop/flujoBagazo/codigo/calibracion/\")\n",
    "from calibracion import graficar, get_names\n",
    "class MakeBackground(MakeBackgroundBasic):\n",
    "    def __init__(self, path)->None:\n",
    "        \"\"\"make background from multiple images\n",
    "\n",
    "        Args:\n",
    "            path (_type_): directory where the images are stored\n",
    "        \"\"\"\n",
    "        self.rgb_names = get_names(path,'rgb', True)\n",
    "        self.depth_names = get_names(path,'depth', True)\n",
    "    \n",
    "    def get_points(self):\n",
    "        uv_points = []\n",
    "        z_values = []\n",
    "        for rgb, depth in zip(self.rgb_names, self.depth_names):\n",
    "            print(rgb)\n",
    "            rgb = cv2.imread(rgb)\n",
    "            depth = cv2.imread(depth, cv2.IMREAD_UNCHANGED)\n",
    "            if not hasattr(self, 'u'):\n",
    "                self.make_uv_cords(depth.shape)\n",
    "                \n",
    "            mask = segmenter(rgb, black_object=True)\n",
    "            img_points, depth_row = self.get_img_points(depth, mask)\n",
    "              \n",
    "            uv_points.append(img_points)\n",
    "            z_values.append(depth_row)\n",
    "        \n",
    "        return np.vstack(uv_points), np.vstack(z_values)\n",
    "    \n",
    "    def get_background_img(self):\n",
    "        uv_points, z_values= self.get_points()\n",
    "        print(uv_points.shape, z_values.shape)\n",
    "        model = linear_model.LinearRegression()\n",
    "        # train model\n",
    "        model.fit(uv_points,z_values)\n",
    "        UV = np.vstack((self.u,self.v)).T # shape = (u*v,2)\n",
    "        background_row = model.predict(UV)\n",
    "        background_img = background_row.reshape(self.shape)\n",
    "        background_img = np.round(background_img,0)\n",
    "        background_img = np.uint16(background_img)\n",
    "        return background_img\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = '/home/ingelec2/Desktop/flujoBagazo/dataset/intel/medicion/200/caja1/640_/'\n",
    "path = '/home/ingelec2/Desktop/flujoBagazo/dataset/intel/medicion_after_cal/volume/200/caja1_/'\n",
    "maker = MakeBackground(path)\n",
    "background_img = maker.get_background_img()\n",
    "background_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(background_img.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maker.save(path,'background',background_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# length measure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# length measures\n",
    "import numpy as np\n",
    "import cv2\n",
    "import sys# las sisguientes dos lineas ayudan a ubicar al archivo calibracion.py\n",
    "sys.path.append(\"/home/ingelec2/Desktop/flujoBagazo/codigo/calibracion/\")\n",
    "from calibracion import graficar, get_names, puntos\n",
    "class longitud(puntos):\n",
    "    # path_configuracion: direcciÃ³n absoluta del lugar donde se encuentra el archivo de configuraciÃ³n\n",
    "    #nombre_configuraciÃ³n: nombre del archivo configuraciÃ³n sin la extensiÃ³n .ini\n",
    "    #d:diametro de circulos en milimetros\n",
    "    # nf: numero de filas del patron\n",
    "    #nc: numero de circulos por fila del patron\n",
    "    def __init__(self,d,nf,nc, depth_inverse):\n",
    "       \n",
    "        puntos.__init__(self,nf,nc)\n",
    "        # variables de isntancia\n",
    "        self.distancia_patron=self.formar_distancia(d)# distancia original entre puntos contiguos del patron. tiene en cuenta que los puntos estan agrupados por fila, los puntos de cada fila estan ordenados de izquierda a derecha, y las filas de arriba hacia abajo.\n",
    "        self.error_promedio=0\n",
    "        self.depth_inversa = depth_inverse\n",
    "    # abre el par de imagenes rgb y profundidad que esten captando la misma escena\n",
    "    #los nombre desben estar en el formato indicador_nombre. indicardor=\"rgb\" para la imagen del sensor rgb\n",
    "    #indicador=\"depth\" para la imagen del sensor de profundidad. \n",
    "    #nobre debera ser el mismo para el par de imagenes que representen la misma escena.\n",
    "    #pasa la imagen rgb al dominio de profundidad\n",
    "    #\n",
    "    def obtener_uvz(self, rgb_img, depth_img):\n",
    "        ret,_,puntos_uv=self.extraer(rgb_img,0)# es una imagen en el dominio de profundidad pero su caracteristicas siguen siendo de color. no necesita mejora\n",
    "        # informar si hubo detecciÃ³n de puntos\n",
    "        print(\"hubo de detecciÃ³n de puntos?: {}\".format(ret))\n",
    "        #obtener cordenada z # numpy indexa fila x columna, opencv indexa ancho por lato. por lo tanto hay que invertir los indices.\n",
    "        z=[]\n",
    "        if ret:  \n",
    "            for punto in puntos_uv:\n",
    "                fila=int(np.around(punto[0][1]))\n",
    "                col=int(np.around(punto[0][0]))\n",
    "                valor=depth_img[fila,col]\n",
    "\n",
    "                z.append(valor)\n",
    "        z=np.array([z])\n",
    "        #dibujar puntos medios sobre la imagen de profundidad\n",
    "        img_puntos=self.dibujar(depth_img,puntos_uv,1)\n",
    "        return ret,puntos_uv,z,img_puntos\n",
    "    # la funciÃ³n resive puntos uv y los trasforma a puntos X,Y,Z\n",
    "    # reproyecta los puntos uv encontrados en la imagen y los lleva al espacio.las cordenadas son cartesians y su origen  es el foco de la camara\n",
    "    def obtener_xyz(self,puntos_uv,z):\n",
    "        \n",
    "        # los puntos estan almacenados en vectores fila [u,v]. para la multiplicacion matricial se los lleva a vectores tipo columna [u;v;1]\n",
    "        puntos_uv=puntos_uv.reshape(-1,2) # desepaquetar. de shape(n,1,2) hacia shape(n,2)\n",
    "        puntos_u=puntos_uv[:,0]# extraer todas las componentes u de los puntos\n",
    "        puntos_v=puntos_uv[:,1]# #extraer todas las componentes v\n",
    "        unos=np.ones(puntos_uv.shape[0])\n",
    "        puntos_uv1=np.array((puntos_u,puntos_v,unos))# formar vectores columna (u;v;1)\n",
    "        puntos_xy1_n=np.dot(self.depth_inversa,puntos_uv1)# calcular cordenadas normalizadas\n",
    "        puntos_xyz=z*puntos_xy1_n# calular cordenadas espaciales de la forma [X;Y;Z]. son vectores columna\n",
    "        #devolver puntos a forma vector fila [(x,y,z)].separando los putos\n",
    "        puntos_xyz=np.concatenate((puntos_xyz[0].reshape(-1,1),puntos_xyz[1].reshape(-1,1),puntos_xyz[2].reshape(-1,1)),axis=1)\n",
    "        return (puntos_xyz) #entregar array de la forma shape(n,3)\n",
    "    #encuentra la distancia euclidiana entre los puntos contiguos XYZ y los compara  con la distancia de construcciÃ³n de los puntos del patron\n",
    "    def calcular_distancia(self,puntos_xyz):\n",
    "        distancias=[]\n",
    "        error_distancias=[]\n",
    "        for i in range(puntos_xyz.shape[0]-1):\n",
    "            vector=puntos_xyz[i+1]-puntos_xyz[i]\n",
    "            distancia=np.sqrt(np.sum(np.power(vector,2)))\n",
    "            distancias.append(distancia)\n",
    "        distancias=np.array(distancias).reshape(-1,1)/10\n",
    "        error_distancias=np.absolute(self.distancia_patron-distancias)\n",
    "        error_distancias=100*error_distancias/self.distancia_patron\n",
    "        self.error_promedio=np.sum(error_distancias)/error_distancias.size\n",
    "        return distancias,error_distancias,self.error_promedio\n",
    "    #la distancia se calcula entre dos puntos contiguos\n",
    "    #d=diametro de los circulos\n",
    "    #nf=numero de filas del patron\n",
    "    #nc=numero de circulos por fila\n",
    "    #los puntos estan agrupados por filas, los puntos de cada fila se encuentran ordenados de izquierda a derecha y las filas de arriba hacia abajo\n",
    "    def formar_distancia(self,d):\n",
    "        nc=self.nc-1# al ser puntos medio entre circulos se pierde un punto por cada fila\n",
    "        distancias_patron=np.ones((self.nf*nc-1,1))#al ser distancia sobre puntos contiguos la informacion disminuye en un dato\n",
    "        #formar distancias teniendo en cuenta la estructura del patron\n",
    "        for i in range(distancias_patron.size):\n",
    "            if (i+1)%nc:# puntos contiguos de una misma fila\n",
    "                distancias_patron[i]=2*d\n",
    "            else:#puntos contiguos, punto extremo derecho fila superior, punto extremo izquierdo fila inferior\n",
    "                if (i+1)%8:# por se patron asimetrico,las distancias entre extremos cambian de una fila a otra\n",
    "                    distancias_patron[i]=np.sqrt((2*(nc-1)*d-d)**2+d**2)#fila impar\n",
    "                else:\n",
    "                    distancias_patron[i]=np.sqrt((2*(nc-1)*d+d)**2+d**2)#fila par\n",
    "        return distancias_patron\n",
    "\n",
    "def open_pair(rgb_pathname,depth_pathname):\n",
    "    rgb = cv2.imread(rgb_pathname)\n",
    "    depth = cv2.imread(depth_pathname, cv2.IMREAD_UNCHANGED)\n",
    "    return rgb, depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path_img = '/home/ingelec2/Desktop/flujoBagazo/dataset/intel/aligment/120/to_rgb_848_480/'\n",
    "depth_inverse = calibration848_480.depth_inv\n",
    "medir=longitud(100,8,5, depth_inverse)\n",
    "rgb_names = get_names(path_img,'rgb', True)\n",
    "depth_names = get_names(path_img,'depth', True)\n",
    "list_mean_error = []\n",
    "for rgb, depth in zip(rgb_names, depth_names):\n",
    "    print(rgb)\n",
    "    print(depth)\n",
    "    rgb, depth = open_pair(rgb,depth)\n",
    "    ret,puntos_uv,z,img_puntos=medir.obtener_uvz(rgb,depth)\n",
    "    if ret:\n",
    "            print(\"distancia media\",z.mean())\n",
    "            xyz=medir.obtener_xyz(puntos_uv,z)\n",
    "            distancias,error_distancias,error_promedio=medir.calcular_distancia(xyz)\n",
    "            list_mean_error.append(error_promedio)\n",
    "            # for i in range(distancias.size):\n",
    "            #     print(\"puntos {} y {} : las siguientes son unidades en milimetros\".format(i,i+1))\n",
    "            #     print(\"distancia calculada:{}\".format(distancias[i]))\n",
    "            #     print(\"distancia original:{}\".format(medir.distancia_patron[i]))\n",
    "            #     print(\"error en porcentaje :{}%\".format(error_distancias[i]))\n",
    "            # print(\"error promedio en porcentaje :{}%\".format(error_promedio))\n",
    "            # graficar([img_puntos],1,1,[\"imagen depth con puntos detectados\"])\n",
    "if  list_mean_error:           \n",
    "    list_mean_error = np.array(list_mean_error)\n",
    "    print('')\n",
    "    print(f'total_mean', list_mean_error.mean())\n",
    "else:\n",
    "    print('check directory')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# area measure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys# las sisguientes dos lineas ayudan a ubicar al archivo calibracion.py\n",
    "sys.path.append(\"/home/ingelec2/Desktop/flujoBagazo/codigo/calibracion/\")\n",
    "from calibracion import graficar, get_names, AreaCal, ConfigHandlerJson\n",
    "from types import FunctionType\n",
    "class IntelArea:\n",
    "    def __init__(self, calibration_data: Calibration)->None:\n",
    "        self.calibration_data = calibration_data\n",
    "        self.TO_METERS = 1/10000\n",
    "        self.AREA_CONSTANT = self.calibration_data.fx*self.calibration_data.fy\n",
    "        area_cali = AreaCal(ConfigHandlerJson().open(path='', filename='intel'))\n",
    "        self.get_area2 = area_cali.get_area\n",
    "        self.ZMIN = 4000\n",
    "        self.ZMAX = 22000\n",
    "    def normalization(self, z_row:np.ndarray) -> np.ndarray:\n",
    "        return (z_row-self.ZMIN)/(self.ZMAX-self.ZMIN)\n",
    "    \n",
    "    def set_model_area(self, coefs: list)->FunctionType:\n",
    "        \"\"\" the coefficients must be sorted as coef[0]xÂ²+coef[1]x+coef[2].\n",
    "        Args:\n",
    "        coefs (list): polynomial coefficients, if area optimization was not implemented the constant area must be inside of a list [constant_area]\n",
    "        \"\"\"\n",
    "        def get_area(z_array: np.ndarray) -> np.ndarray:\n",
    "            \"\"\"\n",
    "            if area_optimization was implemented, z_array must be normalized.\n",
    "            check area optimization was made in the meter units [m].\n",
    "            check are optimization and z_distortion has the same z_min and z_max values used into the normalization.\n",
    "            \"\"\"\n",
    "            z_norm = self.normalization(z_array.copy())\n",
    "            return np.polyval(coefs, z_norm)\n",
    "\n",
    "        return  get_area\n",
    "    \n",
    "    def get_area(self, z_row:np.ndarray):\n",
    "        z_row_copy = self.unify_units(z_row.copy())\n",
    "        return z_row_copy/self.AREA_CONSTANT\n",
    "    \n",
    "    def unify_units(self, depth_img: np.ndarray) -> np.ndarray:\n",
    "        \"\"\" convertion to meter units\"\"\"\n",
    "        return depth_img*self.TO_METERS\n",
    "    \n",
    "    def get_measurement(self, z_img: np.array, mask: np.ndarray) -> float:\n",
    "        \"\"\"\n",
    "        z_img, mask, and ref_image must have the same shape.\n",
    "        example: shape=[480,640].\n",
    "\n",
    "        Args\n",
    "            z_img= this image must have de same units that background_image. \n",
    "            mask (np.ndarray): image with the same shape of z_img, where pixels=1 are the objet pixel to make the measurement.\n",
    "        Returns: float: area measurement [mÂ²]. \n",
    "        \"\"\"\n",
    "        #  unify dimensions to have rows elements that have 1:1 pixel position correspondence betwin all them\n",
    "        #  to make this all images must have de same shape \n",
    "        z_row = z_img.reshape(-1)\n",
    "        # z_row = self.unify_units(z_row)# transform to meters\n",
    "        # print(f'z mean', z_row.mean())\n",
    "        mask_row = mask.reshape(-1)\n",
    "        # find pixel location of the object to make its measure\n",
    "        index = np.where(mask_row == 1)\n",
    "        z_target = z_row[index]\n",
    "        # get are pixel by pixel\n",
    "        area_target = self.get_area2(z_target)\n",
    "        total_area = area_target.sum()\n",
    "        return total_area, z_target.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "class TestMeasure:\n",
    "    def __init__(self, path_images: str,calibration_data)->None:\n",
    "        self.rgb_names = get_names(path= path_images, prefix='rgb', sort= True)\n",
    "        self.depth_names = get_names(path= path_images, prefix='depth', sort= True)\n",
    "        self.meter = IntelArea( calibration_data)\n",
    "        self.segmenter = Segmenter()\n",
    "\n",
    "    def get_areas(self) -> np.ndarray:\n",
    "        results = []\n",
    "        z = []\n",
    "        for rgb_name, depth_name in zip(self.rgb_names, self.depth_names):\n",
    "            print(rgb_name)\n",
    "            rgb = cv2.imread(rgb_name)\n",
    "            depth = cv2.imread(depth_name, cv2.IMREAD_UNCHANGED)\n",
    "            mask = self.segmenter.get_mask(rgb)\n",
    "            print(mask.shape)\n",
    "            img_mascara=cv2.bitwise_and(rgb,rgb,mask=mask)\n",
    "            # print([rgb_name, depth_name])\n",
    "            # graficar([img_mascara], 1,1, list_titulos=[rgb_name, depth_name])\n",
    "            \n",
    "            area, z_mean = self.meter.get_measurement(depth, mask)\n",
    "            print('z mean', z_mean)\n",
    "            print('area', area)\n",
    "            z.append(z_mean)\n",
    "            results.append(area)\n",
    "        return np.array(results), np.array(z)\n",
    "    \n",
    "    def get_error(self, list_measures: np.ndarray, ground_true: float) -> np.ndarray:\n",
    "        lit_error = 100*(list_measures-ground_true)/ground_true\n",
    "        return lit_error\n",
    "    \n",
    "    def draw_hist(self, list_values: np.ndarray) -> None:\n",
    "        plt.hist(list_values)\n",
    "        plt.show()\n",
    "    \n",
    "    def analisis(self,list_error:np.ndarray, z:np.ndarray) -> None:\n",
    "        self.draw_hist(list_error)\n",
    "        print(f'mean error: {list_error.mean()}')\n",
    "        \n",
    "        plt.plot(z,list_error)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patron_volume = 0.46*0.55*0.362# in meters CAJA1\n",
    "patron_area = np.pi*(0.1**2)\n",
    "print(f'patron area: {patron_area}')\n",
    "path = '/home/ingelec2/Desktop/flujoBagazo/dataset/intel/medicion_after_cal/area/area_range/'\n",
    "test = TestMeasure(path,Calibration640_480N)\n",
    "list_areas,z = test.get_areas()# in meters\n",
    "\n",
    "list_errors = test.get_error(list_areas, patron_area)\n",
    "test.analisis(list_errors,z) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.where(z<18000)\n",
    "new_z = z[index]\n",
    "new_e = list_errors[index]\n",
    "plt.plot(new_z, new_e)\n",
    "plt.title(\"Error vs Profundidad\")\n",
    "plt.xlabel(\"[100 um]\")\n",
    "plt.ylabel(\"[%]\")\n",
    "plt.show()\n",
    "plt.hist(new_e)\n",
    "plt.title(\"Error\")\n",
    "plt.xlabel(\"[%]\")\n",
    "print(new_e.mean())\n",
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys# las sisguientes dos lineas ayudan a ubicar al archivo calibracion.py\n",
    "sys.path.append(\"/home/ingelec2/Desktop/flujoBagazo/codigo/calibracion/\")\n",
    "from calibracion import graficar, get_names\n",
    "\n",
    "class IntelVolume():\n",
    "    \n",
    "    def __init__(self, background_img: np.ndarray= None, calibration_data:Calibration= None)->None:\n",
    "        self.calibration_data = calibration_data\n",
    "        self.TO_METERS = 1/10000\n",
    "        self.set_background(background_img)\n",
    "        self.get_area = IntelArea(calibration_data).get_area2\n",
    "        \n",
    "        \n",
    "    def set_background(self, background_img: np.ndarray) -> None:\n",
    "        self.back_ground = self.unify_units(background_img)\n",
    "    \n",
    "    def unify_units(self, depth_img: np.ndarray) -> np.ndarray:\n",
    "        \"\"\" convertion to meter units\"\"\"\n",
    "        return depth_img*self.TO_METERS\n",
    "    \n",
    "    def get_measurement(self, z_img: np.ndarray, mask: np.ndarray) -> float:\n",
    "        \"\"\"\n",
    "        z_img, mask, and ref_image must have the same shape.\n",
    "        example: shape=[480,640].\n",
    "\n",
    "        Args\n",
    "            z_img= this image must have de same units that background_image. \n",
    "            mask (np.ndarray): image with the same shape of z_img, where pixels=1 are the objet pixel to make the measurement.\n",
    "        Returns: float: volume measurement [mÂ³]. at the moment as reference, the first significant digit is at the second decimal. example volume=0.046 mÂ³.where 4 is the first significant digit. if the significant digit is in another position E.g. volume = 0.46  or 0.0046 it's highly probable that an error in units has happend\n",
    "        \"\"\"\n",
    "        #  unify dimensions to have rows elements that have 1:1 pixel position correspondence betwin all them\n",
    "        #  to make this all images must have de same shape \n",
    "        z_row = z_img.reshape(-1)# transform to meters\n",
    "        mask_row = mask.reshape(-1)\n",
    "        ref_row = self.back_ground.copy().reshape(-1)\n",
    "        # find pixel location of the object to make its measure\n",
    "        index = np.where(mask_row == 1)\n",
    "        z_target = z_row[index]\n",
    "        ref_target = ref_row[index]\n",
    "        # get are pixel by pixel\n",
    "        area_target = self.get_area(z_target)\n",
    "         # get  pixel by pixel heigh  of target\n",
    "        z_target = self.unify_units(z_target)\n",
    "        height_target = ref_target-z_target\n",
    "        print('heigh', height_target.mean())\n",
    "        print('area', area_target.sum())\n",
    "#       # get  pixel by pixel volume of target\n",
    "        vol_target = height_target*area_target\n",
    "        # total_vol units must be in mÂ³\n",
    "        total_vol = np.sum(vol_target)\n",
    "        if total_vol < 0:\n",
    "            total_vol = 0\n",
    "        return total_vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from skimage import morphology\n",
    "from typing import List\n",
    "import matplotlib.pyplot as plt\n",
    "        \n",
    "    \n",
    "class TestVolume:\n",
    "    def __init__(self, path_images: str, path_name_background,calibration_data, black_object = True)->None:\n",
    "        self.rgb_names = get_names(path= path_images, prefix='rgb', sort= True)\n",
    "        self.depth_names = get_names(path= path_images, prefix='depth', sort= True)\n",
    "        background_img = cv2.imread(path_name_background, cv2.IMREAD_UNCHANGED)\n",
    "        print('background distance', background_img.mean())\n",
    "        self.meter = IntelVolume(background_img, calibration_data)\n",
    "        self.black_object = black_object\n",
    "    \n",
    "\n",
    "    def get_volumes(self, pnt_init=None, pnt_end=[-1,-1]) -> np.ndarray:\n",
    "        results = []\n",
    "        for rgb_name, depth_name in zip(self.rgb_names, self.depth_names):\n",
    "            print(rgb_name)\n",
    "            rgb = cv2.imread(rgb_name)\n",
    "            depth = cv2.imread(depth_name, cv2.IMREAD_UNCHANGED)\n",
    "            \n",
    "            if pnt_init is not None:# get ROI\n",
    "                rgb = rgb[pnt_init[0]:pnt_end[0], pnt_init[1]:pnt_end[1]]\n",
    "                depth = depth[pnt_init[0]:pnt_end[0], pnt_init[1]:pnt_end[1]]\n",
    "                \n",
    "            mask = segmenter(rgb, black_object= self.black_object)\n",
    "            \n",
    "            img_mascara=cv2.bitwise_and(rgb,rgb,mask=mask)\n",
    "            # print([rgb_name, depth_name])\n",
    "            # graficar([img_mascara], 1,1, list_titulos=[rgb_name, depth_name])\n",
    "            \n",
    "            volume = self.meter.get_measurement(depth, mask)\n",
    "            print('volume', volume)\n",
    "            results.append(volume)\n",
    "        return np.array(results)\n",
    "    \n",
    "    def get_error(self, list_volumes: np.ndarray, patron_volume: float) -> np.ndarray:\n",
    "        lit_error = 100*np.abs(list_volumes-patron_volume)/patron_volume\n",
    "        return lit_error\n",
    "    \n",
    "    def draw_hist(self, list_values: np.ndarray) -> None:\n",
    "        plt.hist(list_values)\n",
    "        plt.title('Error absoluto')\n",
    "        plt.xlabel(\"[%]\")\n",
    "        plt.show()\n",
    "    \n",
    "    def analisis(self,list_error:np.ndarray) -> None:\n",
    "        self.draw_hist(list_error)\n",
    "        print(f'mean error', list_error.mean())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.46*0.55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patron_volume = 0.46*0.55*0.362# in meters box 1\n",
    "print('ground True', patron_volume)\n",
    "# patron_volume = 0.325*0.48*0.375# Box 2\n",
    "# path = '/home/ingelec2/Desktop/flujoBagazo/dataset/intel/medicion/136/caja2/640/'\n",
    "# path = \"/home/ingelec2/Desktop/flujoBagazo/dataset/intel/medicion_after_cal/volume/caja1/137/\"\n",
    "path = \"/home/ingelec2/Desktop/flujoBagazo/dataset/intel/medicion_after_cal/volume/200/caja1_/\"\n",
    "background_name = 'background.png'\n",
    "path_name_background = f'{path}{background_name}'\n",
    "test = TestVolume(path, path_name_background,Calibration640_480N, black_object = False)\n",
    "# list_volumes = test.get_volumes()# in meters\n",
    "list_volumes = test.get_volumes(pnt_init=[10,10],pnt_end=[-50,-100])# in meters\n",
    "\n",
    "list_errors = test.get_error(list_volumes, patron_volume)\n",
    "test.analisis(list_errors) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Volume Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from skimage import morphology\n",
    "from typing import List, Optional\n",
    "import matplotlib.pyplot as plt\n",
    "from calibracion import get_index\n",
    "\n",
    "def recover(img):\n",
    "        mask=img.copy()\n",
    "        mask[mask<3000]=1\n",
    "        mask[mask!=1]=0\n",
    "        mask=mask.astype(np.uint8)\n",
    "        dst = cv2.inpaint(img.copy(),mask,1,cv2.INPAINT_TELEA)\n",
    "        return dst.astype(float)\n",
    "    \n",
    "background_img_maker = MakeBackgroundOneImg()\n",
    "\n",
    "def get_mask_by_depth(depth_img, background_img: Optional[np.ndarray]= None,diff_thr=500):\n",
    "    \"\"\"consider 2 object One in front the other. the segmentation have in main that the back object is predominant and parallel to the camera.\n",
    "\n",
    "    Args:\n",
    "        diff_thr (float): mean difference in [um] between the back object and front. this could consider as the half height of the front object too\n",
    "    Returns:\n",
    "        mask: numpy array one chanel\n",
    "    \"\"\"\n",
    "    if background_img is None:\n",
    "        background_img =  background_img_maker.get_background_img(depth_img)\n",
    "    delta_img = background_img - depth_img\n",
    "    mask = np.zeros_like(depth_img, dtype= np.uint8)\n",
    "   \n",
    "    mask[delta_img>=diff_thr] = 1\n",
    "    return mask\n",
    "\n",
    "class VolumeInRange:\n",
    "    def __init__(self, path_images: str,calibration_data, black_object = True)->None:\n",
    "        self.rgb_names = get_names(path= path_images, prefix='rgb', sort= True)\n",
    "        self.depth_names = get_names(path= path_images, prefix='depth', sort= True)\n",
    "        \n",
    "        self.meter = IntelVolume(background_img=0,calibration_data=calibration_data)\n",
    "        self.black_object = black_object\n",
    "        self.make_background_img = MakeBackgroundOneImg()\n",
    "        self.background_img = None\n",
    "\n",
    "    def get_volumes(self, pnt_init=None, pnt_end=[-1,-1]) -> np.ndarray:\n",
    "        results = []\n",
    "        z = []\n",
    "        for rgb_name, depth_name in zip(self.rgb_names, self.depth_names):\n",
    "            print(rgb_name)\n",
    "            rgb = cv2.imread(rgb_name)\n",
    "            depth = cv2.imread(depth_name, cv2.IMREAD_UNCHANGED)\n",
    "            \n",
    "            if pnt_init is not None:# get ROI\n",
    "                rgb = rgb[pnt_init[0]:pnt_end[0], pnt_init[1]:pnt_end[1]]\n",
    "                depth = depth[pnt_init[0]:pnt_end[0], pnt_init[1]:pnt_end[1]]\n",
    "            depth_copy = depth.astype(float)\n",
    "            depth = recover(depth)\n",
    "            \n",
    "            index = get_index(rgb_name, 'rgb')\n",
    "            print('index:', index)\n",
    "            if (index)%5==0:\n",
    "                background_img = self.make_background_img.get_background_img(depth)\n",
    "                self.background_img = background_img.copy()\n",
    "                # graficar([background_img,], 1,1)\n",
    "                self.meter.set_background(background_img)\n",
    "                \n",
    "\n",
    "            mask = get_mask_by_depth(depth_copy, background_img=self.background_img, diff_thr=1000)\n",
    "            \n",
    "            img_mascara=cv2.bitwise_and(rgb,rgb,mask=mask)\n",
    "            # print([rgb_name, depth_name])\n",
    "            graficar([img_mascara], 1,1, list_titulos=[rgb_name])\n",
    "            \n",
    "            volume = self.meter.get_measurement(depth, mask)\n",
    "            print('volume', volume)\n",
    "            results.append(volume)\n",
    "            z.append(self.meter.back_ground.mean())\n",
    "        return np.array(results), np.array(z)\n",
    "    \n",
    "    def get_error(self, list_volumes: np.ndarray, patron_volume: float) -> np.ndarray:\n",
    "        lit_error = 100*np.abs(list_volumes-patron_volume)/patron_volume\n",
    "        return lit_error\n",
    "    \n",
    "    def draw_hist(self, list_values: np.ndarray) -> None:\n",
    "        plt.hist(list_values)\n",
    "        plt.title('Error absoluto')\n",
    "        plt.xlabel(\"[%]\")\n",
    "        plt.show()\n",
    "    \n",
    "    def analisis(self,list_error:np.ndarray, z) -> None:\n",
    "        self.draw_hist(list_error)\n",
    "        print(f'mean error', list_error.mean())\n",
    "        plt.plot(z,list_error)\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patron_volume = 0.2*0.22*0.19# in meters, area*depth \n",
    "print('ground True', patron_volume)\n",
    "path = \"/home/ingelec2/Desktop/flujoBagazo/dataset/intel/medicion_after_cal/volume/range/\"\n",
    "test = VolumeInRange(path,Calibration640_480N, black_object = True)\n",
    "# list_volumes = test.get_volumes()# in meters\n",
    "list_volumes, list_z = test.get_volumes(pnt_init=[100,100],pnt_end=[-50,-100])# in meters\n",
    "\n",
    "list_errors = test.get_error(list_volumes, patron_volume)\n",
    "test.analisis(list_errors, list_z) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3c25e185183312141286a352e3e4d38d8c26e9d34360093b8c9178a570d74532"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
